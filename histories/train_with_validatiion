def train_model(config, data_dir, epochs,  last_epoch=None):

    train_files = os.listdir(data_dir)
    device = torch.device("cuda:0")
    model = AENet()
    model = nn.DataParallel(model)
    model.to(device)

    criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([0.2, 5]).to(device))
    optimizer = optim.Adam(model.parameters(), lr=config["lr"], weight_decay=config["weight_decay"])

    checkpoint_dir = "C:/Users/vlank/PycharmProjects/Antispoof1/checkpoints_clf"
    os.makedirs(checkpoint_dir, exist_ok=True)
    checkpoint_file = os.path.join(checkpoint_dir, f"checkpoint_{last_epoch}_clf.pt")

    if (last_epoch is None) or not os.path.exists(checkpoint_file):
        print("Last epoch file does not exist!")
        clf = SGDClassifier(loss='log_loss', class_weight={0: 1, 1: 10})
        start_epoch = 0
    else:
        checkpoint_data = torch.load(checkpoint_file)
        start_epoch = checkpoint_data["epoch"] + 1
        model.load_state_dict(checkpoint_data["model_state_dict"])
        optimizer.load_state_dict(checkpoint_data["optimizer_state_dict"])
        clf = checkpoint_data['classifier']

    precision_by_epoch = []
    recall_by_epoch = []
    losses_by_epoch = []

    for epoch in range(start_epoch, start_epoch + epochs):
        print(f"EPOCH {epoch}")
        val_loss = 0.0
        val_preds = []
        val_targets = []

        for i, file_name in enumerate(train_files):
            if i >= 0:
                print(f"package {i}...")
                dataset = CelebaDataset(os.path.join(train_dir, file_name))
                train_size = int(len(dataset) * 0.8)
                val_size = len(dataset) - train_size
                train_dataset, val_dataset = random_split(dataset, [train_size, val_size])
                train_dataloader = DataLoader(train_dataset, batch_size=config["batch_size"], shuffle=True)
                val_dataloader = DataLoader(val_dataset, batch_size=config["batch_size"], shuffle=False)

                model.train()
                for images, labels in tqdm(train_dataloader):
                    images, labels = images.to(device), labels.to(device)
                    optimizer.zero_grad()
                    outputs = model(images)
                    loss = criterion(outputs, labels)
                    loss.backward()
                    optimizer.step()
                    clf.partial_fit(outputs.detach().cpu().numpy(), torch.argmax(labels, dim=1).detach().cpu().numpy(),
                                    np.unique(labels.detach().cpu()))

                temp_val_loss = 0.0
                temp_val_preds = []
                temp_val_targets = []

                model.eval()
                with torch.no_grad():
                    for images, labels in tqdm(val_dataloader):
                        images, labels = images.to(device), labels.to(device)
                        outputs = model(images)
                        loss = criterion(outputs, labels)
                        temp_val_loss += loss.item()
                        temp_val_preds += list(clf.predict(outputs.detach().cpu().numpy()))
                        temp_val_targets += list(torch.argmax(labels, dim=1).detach().cpu().numpy())
                print(f"Package val loss: {temp_val_loss}")
                print(f"Package val precision: {precision_score(temp_val_targets, temp_val_preds, average='weighted')}")
                print(f"Package val recall: {recall_score(temp_val_targets, temp_val_preds, average='weighted')}")
                val_loss += temp_val_loss
                val_preds += temp_val_preds
                val_targets += temp_val_targets

        precision = precision_score(val_targets, val_preds, average='weighted')
        recall = recall_score(val_targets, val_preds, average='weighted')
        losses_by_epoch.append(val_loss)
        recall_by_epoch.append(recall)
        precision_by_epoch.append(precision)
        print(f"Epoch val loss: {val_loss}")
        print(f"Epoch val precision: {precision}")
        print(f"Epoch val recall: {recall}")

        checkpoint_data = {
            "epoch": epoch,
            "model_state_dict": model.state_dict(),
            "optimizer_state_dict": optimizer.state_dict(),
            'classifier': clf,
            "val_loss": val_loss,
            "val_precision": precision,
            "val_recall": recall
        }
        if mode == "clf":
            checkpoint_path = os.path.join(checkpoint_dir, f"checkpoint_{epoch}_clf.pt")
        else:
            checkpoint_path = os.path.join(checkpoint_dir, f"checkpoint_{epoch}_cond.pt")
        torch.save(checkpoint_data, checkpoint_path)